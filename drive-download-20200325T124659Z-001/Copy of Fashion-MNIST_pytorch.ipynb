{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Fashion-MNIST_pytorch.ipynb","provenance":[{"file_id":"1awByMa2Yet-Uhkn7PcxAnzgjgwHaHHbN","timestamp":1581612266847}],"collapsed_sections":[],"authorship_tag":"ABX9TyPa4xbYmDy2LjpVXBBkcvIT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0XKW0uWItfW9","colab_type":"code","colab":{}},"source":["import torchvision\n","import torch\n","import numpy as np\n","from fastai.vision import *\n","from fastai import *\n","from torchvision import transforms"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jUr4j3dmH3_4","colab_type":"code","outputId":"742dd938-1950-4e82-9b26-608947cfc0a3","executionInfo":{"status":"ok","timestamp":1581665138413,"user_tz":-240,"elapsed":1220,"user":{"displayName":"Baka F","photoUrl":"","userId":"05022197215042441803"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# import standard PyTorch modules\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n","\n","# import torchvision module to handle image manipulation\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# calculate train time, writing train data to files etc.\n","import time\n","import pandas as pd\n","import json\n","from IPython.display import clear_output\n","\n","torch.set_printoptions(linewidth=120)\n","torch.set_grad_enabled(True)     # On by default, leave it here for clarity"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7fcc87fc09b0>"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"G-AYu5jy8WN0","colab_type":"code","colab":{}},"source":["\n","\n","# Helper class, help track loss, accuracy, epoch time, run time, \n","# hyper-parameters etc. Also record to TensorBoard and write into csv, json\n","class RunManager():\n","  def __init__(self, tensorboard=False):\n","\n","    # tracking every epoch count, loss, accuracy, time\n","    self.epoch_count = 0\n","    self.epoch_loss = 0\n","    self.epoch_num_correct = 0\n","    self.epoch_start_time = None\n","\n","    # tracking every run count, run data, hyper-params used, time\n","    self.run_params = None\n","    self.run_count = 0\n","    self.run_data = []\n","    self.run_start_time = None\n","\n","    # record model, loader and TensorBoard \n","    self.network = None\n","    self.train_loader = None\n","    self.valid_loader = None\n","\n","    self.tb = tensorboard\n","\n","  # record the count, hyper-param, model, loader of each run\n","  # record sample images and network graph to TensorBoard  \n","  def begin_run(self, network, loader):\n","\n","    self.run_start_time = time.time()\n","\n","    self.run_count += 1\n","\n","    self.network = network\n","    self.loader = loader\n","\n","    if self.tb:\n","        self.tb = SummaryWriter(comment=f'-run')\n","        # images, labels = next(iter(self.train_loader))\n","        grid = torchvision.utils.make_grid(images)\n","        self.tb.add_image('images', grid)\n","        self.tb.add_graph(self.network, images)\n","\n","  # when run ends, close TensorBoard, zero epoch count\n","  def end_run(self):\n","    if self.tb:\n","        self.tb.close()\n","        self.epoch_count = 0\n","\n","  # zero epoch count, loss, accuracy, \n","  def begin_epoch(self):\n","    self.epoch_start_time = time.time()\n","\n","    self.epoch_count += 1\n","    self.epoch_loss = 0\n","    self.epoch_num_correct = 0\n","\n","\n","  def end_epoch(self):\n","    # calculate epoch duration and run duration(accumulate)\n","    epoch_duration = time.time() - self.epoch_start_time\n","    run_duration = time.time() - self.run_start_time\n","\n","    # record epoch loss and accuracy\n","    loss = self.epoch_loss / len(self.loader.dataset)\n","    accuracy = self.epoch_num_correct / len(self.loader.dataset)\n","\n","    # Record epoch loss and accuracy to TensorBoard \n","    if self.tb:\n","        self.tb.add_scalar('Loss', loss, self.epoch_count)\n","        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n","\n","    # Record params to TensorBoard\n","    if self.tb:\n","        for name, param in self.network.named_parameters():\n","            self.tb.add_histogram(name, param, self.epoch_count)\n","            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n","    \n","    # Write into 'results' (OrderedDict) for all run related data\n","    results = OrderedDict()\n","    results[\"run\"] = self.run_count\n","    results[\"epoch\"] = self.epoch_count\n","    results[\"loss\"] = loss\n","    results[\"accuracy\"] = accuracy\n","    results[\"epoch duration\"] = epoch_duration\n","    results[\"run duration\"] = run_duration\n","\n","    # Record hyper-params into 'results'\n","    # for k,v in self.run_params._asdict().items(): results[k] = v\n","    self.run_data.append(results)\n","    df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n","\n","    # display epoch information and show progress\n","    clear_output(wait=True)\n","    display(df)\n","\n","  # accumulate loss of batch into entire epoch loss\n","  def track_loss(self, loss):\n","    # multiply batch size so variety of batch sizes can be compared\n","    self.epoch_loss += loss.item() * self.loader.batch_size\n","\n","  # accumulate number of corrects of batch into entire epoch num_correct\n","  def track_num_correct(self, preds, labels):\n","    self.epoch_num_correct += self._get_num_correct(preds, labels)\n","\n","  @torch.no_grad()\n","  def _get_num_correct(self, preds, labels):\n","    return preds.argmax(dim=1).eq(labels).sum().item()\n","  \n","  # save end results of all runs into csv, json for further analysis\n","  def save(self, fileName):\n","\n","    pd.DataFrame.from_dict(\n","        self.run_data, \n","        orient = 'columns',\n","    ).to_csv(f'{fileName}.csv')\n","\n","    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n","      json.dump(self.run_data, f, ensure_ascii=False, indent=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nzJOIhriTMRH","colab_type":"code","colab":{}},"source":["import time\n","\n","import numpy as np\n","import torch\n","from torch import optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torchvision import datasets\n","from matplotlib import pyplot as plt\n","\n","from tqdm import tqdm\n","\n","from PIL import Image\n","\n","\n","def prepare_loader(train_dir, test_dir, transform_train, test_transforms,\n","                   batch_size=64, test_size=0.2, num_workers=0):\n","    \"\"\"\n","    Helper function for prepare data loader\n","    :param train_dir: train data directory\n","    :param test_dir: test data directory\n","    :param transform_train: train transform\n","    :param test_transforms: test transform\n","    :param batch_size: batch size, default 64\n","    :param test_size: test split percentage, default 20%\n","    :param num_workers: num of worker, default 0\n","    :return: train loader and test loader\n","    \"\"\"\n","\n","    # data set\n","    train_data = datasets.ImageFolder(train_dir, transform=transform_train)\n","    test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n","\n","    # obtain training indices that will be used for validation\n","    num_train = len(train_data)\n","\n","    # mix data\n","    # index of num of train\n","    indices = list(range(num_train))\n","    # random the index\n","    np.random.shuffle(indices)\n","    split = int(np.floor(test_size * num_train))\n","    # divied into two part\n","    train_idx, test_idx = indices[split:], indices[:split]\n","\n","    # define the sampler\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    test_sampler = SubsetRandomSampler(test_idx)\n","\n","    # prepare loaders\n","    train_loader = torch.utils.data.DataLoader(\n","        train_data, batch_size=batch_size,\n","        sampler=train_sampler, num_workers=num_workers)\n","\n","    test_loader = torch.utils.data.DataLoader(\n","        test_data, batch_size=batch_size,\n","        sampler=test_sampler, num_workers=num_workers)\n","\n","    print(\"Train size:{}\".format(num_train))\n","    print(\"Test size:{}\".format(len(test_data)))\n","\n","    return [train_loader, test_loader]\n","\n","\n","def load_latest_model(model, name=\"model.pt\"):\n","    \"\"\"\n","    Helper function for Load model\n","    :param model: current model\n","    :param name: model name\n","    :return: loaded model default model.pt\n","    \"\"\"\n","    model.load_state_dict(torch.load(name))\n","    return model\n","\n","\n","def save_current_model(model, name='model.pt'):\n","    \"\"\"\n","    Helper function for save model\n","    :param model: current model\n","    :param name: model name, default model.pt\n","    :return: None\n","    \"\"\"\n","    torch.save(model.state_dict(), name)\n","\n","\n","def save_check_point(model, epoch, train_loader, classes, optimizer, scheduler=None,\n","                     path=None, name='model.pt'):\n","    \"\"\"\n","    Helper function for save check point. save everything like epoch\n","    optimizer state and also model state\n","    :param model: current model\n","    :param epoch: total epoch\n","    :param train_loader: train data loader for extract class_to_idx\n","    :param classes: total classes in your datasets\n","    :param optimizer: optimizer\n","    :param scheduler: scheduler if any, default None\n","    :param path: path for saving model, default None\n","    :param name: model name, default model.pt\n","    :return: None\n","    \"\"\"\n","\n","    class_to_idx = train_loader.dataset.class_to_idx\n","\n","    try:\n","        classifier = model.classifier\n","    except AttributeError:\n","        classifier = model.fc\n","\n","    checkpoint = {\n","        'class_to_idx': class_to_idx,\n","        'class_to_name': classes,\n","        'epochs': epoch,\n","        'classifier': classifier,\n","        'state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict()\n","    }\n","\n","    if scheduler is not None:\n","        checkpoint['scheduler_state_dict'] = scheduler.state_dict()\n","\n","    if path is None:\n","        d = model\n","    else:\n","        d = path + \"/\" + name\n","\n","    torch.save(checkpoint, d)\n","    print(f\"Model saved at {d}\")\n","\n","\n","def load_checkpoint(path, model, optimizer_name='adam', lr=0.003, momentum=None,\n","                    scheduler=None, step=2, gamma=0.1):\n","    \"\"\"\n","    Helper function for load check point\n","    :param path: path of saved model\n","    :param model: current model\n","    :param optimizer_name: optimizer name, default Adam\n","    :param lr: learning rate, used to create optimizer\n","    :param momentum: momentum if you use SGD optimizer, default None\n","    :param scheduler: StepLR scheduler, if you want to create scheduler, default None\n","    :param step: Period of learning rate decay, default 2\n","    :param gamma: Multiplicative factor of learning rate decay. default: 0.1\n","    :return: model, optimizer and scheduler(if scheduler is not None)\n","    \"\"\"\n","\n","    # Make sure to set parameters as not trainable\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    # Load in checkpoint\n","    if torch.cuda.is_available():\n","        checkpoint = torch.load(path)\n","    else:\n","        checkpoint = torch.load(path, map_location=\"cpu\")\n","\n","    # Extract classifier\n","    classifier = checkpoint['classifier']\n","    # set classifier\n","    try:\n","        check = model.classifier\n","    except AttributeError:\n","        check = False\n","\n","    if check is not False:\n","        model.classifier = classifier\n","    else:\n","        model.fc = classifier\n","\n","    # Extract others\n","    model.cat_to_name = checkpoint['class_to_name']\n","    model.class_to_idx = checkpoint['class_to_idx']\n","    model.epochs = checkpoint['epochs']\n","\n","    # Load in the state dict\n","    model.load_state_dict(checkpoint['state_dict'])\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","\n","    if optimizer_name.lower() == 'adam':\n","        optimizer = optim.Adam(model.parameters(), lr=lr)\n","    elif optimizer_name.lower() == \"sgd\":\n","        if momentum is not None:\n","            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","        else:\n","            optimizer = optim.SGD(model.parameters(), lr=lr)\n","    elif optimizer_name.lower() == \"adadelta\":\n","        optimizer = optim.Adadelta(model.parameters(), lr=lr)\n","    else:\n","        optimizer = optim.SGD(model.parameters(), lr=lr)\n","\n","    # load optimizer\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","    if scheduler is not None:\n","        scheduler = lr_scheduler.StepLR(optimizer, step_size=step, gamma=gamma)\n","        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","\n","    total_params = sum(p.numel() for p in model.parameters())\n","    print(f'{total_params:,} total parameters.')\n","    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f'{total_trainable_params:,} total gradient parameters.')\n","    print(f'Model has been trained for {model.epochs} epochs.')\n","\n","    if scheduler is not None:\n","        return [model, optimizer, scheduler]\n","    else:\n","        return [model, optimizer]\n","\n","\n","def freeze_parameters(model):\n","    \"\"\"\n","    Helper function for freeze parameter\n","    :param model: current model\n","    :return: new model with freeze parameters\n","    \"\"\"\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    return model\n","\n","\n","def unfreeze(model):\n","    \"\"\"\n","    Helper function for unfreeze parameters\n","    :param model: current model\n","    :return: new model with unfreeze parameters\n","    \"\"\"\n","    for param in model.parameters():\n","        param.requires_grad = True\n","\n","    return model\n","\n","\n","def train(model, train_loader, test_loader,\n","          epochs, optimizer, criterion, scheduler=None,\n","          name=\"model.pt\", path=None):\n","    \"\"\"\n","    Helper function for train model\n","    :param model: current model\n","    :param train_loader: train data loader\n","    :param test_loader: test data loader\n","    :param epochs: number of epoch\n","    :param optimizer: optimizer\n","    :param criterion: loss function\n","    :param scheduler: scheduler, default None\n","    :param name: model name, default model.pt\n","    :param path: model saved location, default None\n","    :return: model, list of train loss and test loss\n","    \"\"\"\n","\n","    m = RunManager()    \n","    # compare overfitted\n","    train_loss_data, valid_loss_data = [], []\n","    # check for validation loss\n","    valid_loss_min = np.Inf\n","    # calculate time\n","    since = time.time()\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    m.begin_run(model, test_loader)\n","    \n","    for epoch in range(epochs):\n","        # monitor training loss\n","        train_loss = 0.0\n","        valid_loss = 0.0\n","        total = 0\n","        correct = 0\n","        e_since = time.time()\n","\n","        ###################\n","        # train the model #\n","        ###################\n","        model.train()  # prep model for training\n","        if scheduler is not None:\n","            scheduler.step()  # step up scheduler\n","        \n","        for images, labels in tqdm(iterable=train_loader, total=len(train_loader)):\n","            # Move input and label tensors to the default device\n","            images, labels = images.to(device), labels.to(device)\n","            # clear the gradients of all optimized variables\n","            optimizer.zero_grad()\n","            # forward pass: compute predicted outputs by passing inputs to the model\n","            log_ps = model(images)\n","            # calculate the loss\n","            loss = criterion(log_ps, labels)\n","            # backward pass: compute gradient of the loss with respect to model parameters\n","            loss.backward()\n","            # perform a single optimization step (parameter update)\n","            optimizer.step()\n","            # update running training loss\n","            train_loss += loss.item() * images.size(0)\n","\n","\n","        m.begin_epoch()\n","        ######################\n","        # validate the model #\n","        ######################\n","        # print(\"\\n Going for validation\")\n","        model.eval()  # prep model for evaluation\n","        for data, target in test_loader:\n","            # Move input and label tensors to the default device\n","            data, target = data.to(device), target.to(device)\n","            # forward pass: compute predicted outputs by passing inputs to the model\n","            output = model(data)\n","            # calculate the loss\n","            loss_p = criterion(output, target)\n","            # update running validation loss\n","            valid_loss += loss_p.item() * data.size(0)\n","            # calculate accuracy\n","            proba = torch.exp(output)\n","            top_p, top_class = proba.topk(1, dim=1)\n","            equals = top_class == target.view(*top_class.shape)\n","            # accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","\n","            _, predicted = torch.max(output.data, 1)\n","            total += target.size(0)\n","            correct += (predicted == target).sum().item()\n","\n","            m.track_loss(loss_p)\n","            m.track_num_correct(output, target)\n","        m.end_epoch()\n","\n","        # print training/validation statistics\n","        # calculate average loss over an epoch\n","        train_loss = train_loss / len(train_loader.dataset)\n","        valid_loss = valid_loss / len(test_loader.dataset)\n","\n","        # calculate train loss and running loss\n","        train_loss_data.append(train_loss * 100)\n","        valid_loss_data.append(valid_loss * 100)\n","\n","\n","        # save model if validation loss has decreased\n","        if valid_loss <= valid_loss_min:\n","            torch.save(model.state_dict(), name)\n","            valid_loss_min = valid_loss\n","            # save to google drive\n","            if path is not None:\n","                torch.save(model.state_dict(), path)\n","\n","\n","    m.end_run()\n","    # compare total time\n","\n","    # return the model\n","    return [model, train_loss_data, valid_loss_data]\n","\n","\n","def train_faster_log(model, train_loader, test_loader,\n","                     epochs, optimizer, criterion, scheduler=None, print_every=5):\n","    \"\"\"\n","    Helper function for train model. This model print log after a certain interval\n","    in every epoch.\n","    :param model: current model\n","    :param train_loader: train data loader\n","    :param test_loader: test data loader\n","    :param epochs: number of epoch\n","    :param optimizer: optimizer\n","    :param criterion: loss function\n","    :param scheduler scheduler, default None\n","    :param print_every: print log interval\n","    :return:\n","    \"\"\"\n","\n","    steps = 0\n","    running_loss = 0\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    for epoch in range(epochs):\n","        for inputs, labels in train_loader:\n","            steps += 1\n","            # Move input and label tensors to the default device\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            logps = model.forward(inputs)\n","            loss = criterion(logps, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            if steps % print_every == 0:\n","                test_loss = 0\n","                accuracy = 0\n","                model.eval()\n","                with torch.no_grad():\n","                    for inputs, labels in test_loader:\n","                        inputs, labels = inputs.to(device), labels.to(device)\n","                        logps = model.forward(inputs)\n","                        batch_loss = criterion(logps, labels)\n","\n","                        test_loss += batch_loss.item()\n","\n","                        # Calculate accuracy\n","                        ps = torch.exp(logps)\n","                        top_p, top_class = ps.topk(1, dim=1)\n","                        equals = top_class == labels.view(*top_class.shape)\n","                        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","\n","                print(f\"Epoch {epoch + 1}/{epochs}.. \"\n","                      f\"Train loss: {running_loss / print_every:.3f}.. \"\n","                      f\"Test loss: {test_loss / len(test_loader):.3f}.. \"\n","                      f\"Test accuracy: {accuracy / len(test_loader):.3f}\")\n","                running_loss = 0\n","                model.train()\n","\n","    if scheduler is not None:\n","        scheduler.step()\n","\n","    return model\n","\n","\n","def check_overfitted(train_loss, test_loss):\n","    \"\"\"\n","    Helper function for check over fitting\n","    :param train_loss: list of train loss\n","    :param test_loss: list of test loss\n","    :return: None\n","    \"\"\"\n","    plt.plot(train_loss, label=\"Training loss\")\n","    plt.plot(test_loss, label=\"validation loss\")\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(frameon=False)\n","\n","\n","def test_per_class(model, test_loader, criterion, classes):\n","    \"\"\"\n","    Helper function for testing per class\n","    :param model: current model\n","    :param test_loader: test loader\n","    :param criterion: loss function\n","    :param classes: list of classes\n","    :return: None\n","    \"\"\"\n","\n","    total_class = len(classes)\n","\n","    test_loss = 0.0\n","    class_correct = list(0. for i in range(total_class))\n","    class_total = list(0. for i in range(total_class))\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model.eval()  # prep model for evaluation\n","\n","    for data, target in test_loader:\n","        # Move input and label tensors to the default device\n","        data, target = data.to(device), target.to(device)\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the loss\n","        loss = criterion(output, target)\n","        # update test loss\n","        test_loss += loss.item() * data.size(0)\n","        # convert output probabilities to predicted class\n","        _, pred = torch.max(output, 1)\n","        # compare predictions to true label\n","        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n","        # calculate test accuracy for each object class\n","        \n","        for i in range(target.shape[0]):\n","            label = target.data[i]\n","            class_correct[label] += correct[i].item()\n","            class_total[label] += 1\n","\n","    # calculate and print avg test loss\n","    test_loss = test_loss / len(test_loader.dataset)\n","    print('Test Loss: {:.6f}\\n'.format(test_loss))\n","\n","    for i in range(total_class):\n","        if class_total[i] > 0:\n","            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n","                str(i), 100 * class_correct[i] / class_total[i],\n","                np.sum(class_correct[i]), np.sum(class_total[i])))\n","        else:\n","            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n","\n","    print('\\n Test Accuracy (Overall): %2d%% (%2d/%2d)' % (\n","        100. * np.sum(class_correct) / np.sum(class_total),\n","        np.sum(class_correct), np.sum(class_total)))\n","\n","\n","def test(model, loader, criterion=None):\n","    \"\"\"\n","    Helper function for test result. This function use torch.mean()\n","    :param model: current result\n","    :param loader: test data loader\n","    :param criterion: loss function to track loss, default None\n","    :return: None\n","    \"\"\"\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    test_loss = 0\n","    accuracy = 0\n","\n","    with torch.no_grad():\n","        model.eval()\n","\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            logps = model.forward(inputs)\n","\n","            if criterion is not None:\n","                batch_loss = criterion(logps, labels)\n","                test_loss += batch_loss.item()\n","\n","            # Calculate accuracy\n","            ps = torch.exp(logps)\n","            top_p, top_class = ps.topk(1, dim=1)\n","            equals = top_class == labels.view(*top_class.shape)\n","            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","\n","    if criterion is not None:\n","        print(\"Test Loss:{:.6f}\".format(test_loss),\n","              \"\\nAccuracy: {:.4f}\".format(accuracy / len(loader) * 100))\n","    else:\n","        print(\"Accuracy: {:.4f}\".format(accuracy / len(loader) * 100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CydLhPIX3ACl","colab_type":"code","colab":{}},"source":["# Use standard FashionMNIST dataset\n","train_set = torchvision.datasets.FashionMNIST(\n","    root = './data/FashionMNIST',\n","    train = True,\n","    download = True,\n","    transform = transforms.Compose([\n","        transforms.ToTensor()                                 \n","    ])\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EH9ybHMl3qnD","colab_type":"code","outputId":"483df2e0-59f5-452c-927f-482da15c6e50","executionInfo":{"status":"ok","timestamp":1581665139680,"user_tz":-240,"elapsed":2438,"user":{"displayName":"Baka F","photoUrl":"","userId":"05022197215042441803"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(train_set)"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["60000"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"FOKdnRfp2idI","colab_type":"code","colab":{}},"source":["import random\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from skimage.io import imread as gif_imread\n","\n","def visualize(**images):\n","    n = len(images)\n","    plt.figure(figsize=(16, 5))\n","    for i, (name, image) in enumerate(images.items()):\n","        plt.subplot(1, n, i + 1)\n","        # plt.xticks([])\n","        # plt.yticks([])\n","        plt.title(' '.join(name.split('_')).title())\n","        plt.imshow(image[0])\n","    plt.show()\n","\n","def show(index, dataset, transforms=None):\n","\n","    image = dataset[index][0]\n","    target = dataset[index][1]\n","\n","    visualize(image=image)\n","    print('target is: ', target)\n","\n","def show_random(dataset, transforms=None):\n","    length = len(dataset)\n","    index = random.randint(0, length - 1)\n","    show(index, dataset, transforms)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGcjYwRv4v7N","colab_type":"code","outputId":"b6bf9f17-b6c6-434d-8129-1884e583e3d1","executionInfo":{"status":"ok","timestamp":1581665140138,"user_tz":-240,"elapsed":2867,"user":{"displayName":"Baka F","photoUrl":"","userId":"05022197215042441803"}},"colab":{"base_uri":"https://localhost:8080/","height":353}},"source":["show_random(train_set)"],"execution_count":58,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAATEAAAE/CAYAAAAub/QYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYxklEQVR4nO3de5CddX3H8c93z95vuZCYBIhcQkC5\naKgBrEBFUQTUAeqMNVjFGW2YVhx0HEeGtso4Y4dpEezYFhuEijOAUgVlRqoi1aJCkYAMAQIkhBCy\nLBtz3+xmb+d8+8c+mS5hl993syd79hfer5lMdp/zze/8nvNsPuc5Z7/P75i7CwByVVfrCQDAVBBi\nALJGiAHIGiEGIGuEGICsEWIAskaIAcgaIYYpM7ONZva+Ws8Db0yEGICsEWKoGjP7lJn9zsxuMLOd\nZrbBzN5VbH/JzLaY2WVj6j9oZn8ws93F7dfsN94nzexFM9tmZn8/9ozPzOrM7Coze764/U4zmzvN\nu4wZgBBDtZ0h6QlJh0m6XdL3JZ0m6ThJfynpX8ysvajtk/RJSbMlfVDSX5vZxZJkZidK+jdJH5e0\nSNIsSUeMuZ/PSbpY0rslHS5ph6R/PZg7hpnJuHYSU2VmGyV9RtKRkv7W3ZcW20/RaKAtdPeeYts2\nSee6++PjjPNNSe7uXzCzr0h6q7uvKG5rlbRT0oXu/kszWyvpCne/v7h9kaRNklrcfeTg7jFmkvpa\nTwCHnJ4xX++VpH0BNmZbuySZ2RmSrpV0sqRGSU2S/rOoO1zSS/v+kbv3FwG4z1GS7jazyphtZUkL\nJHVVZU+QBV5OopZul3SPpMXuPkvStyVZcVu3Rs/sJElm1qLRl6j7vCTpAnefPeZPs7sTYG8whBhq\nqUPSdncfMLPTJV065rYfSvpw8YuBRknX6P8DThoNvK+b2VGSZGbzzeyiaZo3ZhBCDLX0N5K+Zma9\nkr4i6c59N7j7Uxp98/77Gj0r2yNpi6TBouSfNXoW94vi3/+vRn+pgDcY3thHForfaO6UtNTdX6j1\nfDBzcCaGGcvMPmxmrWbWJuk6SWskbaztrDDTEGKYyS6S9HLxZ6mkjzkvHbAfXk4CyBpnYgCyRogB\nyNq0duw3WpM3q2067/LQ0N6SLBlpru7zUf3WvqqON918VmuobqjT0kWS6vtj91valvfjNpP1asdW\nd5+///YphZiZna/Rfp2SpO+4+7WvV9+sNp1h507lLt+QKqcuS9bsOCEddJLkpdh9zlv1UKwwoi54\np5Vy1e5y8OzTQnWbzovNbf6jsbCb/b0qPm54lV/6D18cb/sBP32bWUmjqwZcIOlESSuKlQcAYNpM\n5TXI6ZLWu/sGdx/SaGc1l30AmFZTCbEjNGaVAUmb9er1ngDgoDvob+yb2UpJKyWpWbE3WwEgaipn\nYl2SFo/5/kiNs46Tu69y9+XuvrxBTVO4OwB4ramE2COSlprZMcVSKR/T6KoCADBtDvjlpLuPmNkV\nkn6u0RaLW4rlUwBg2kzpPTF3v1fSvVWaCwBMGmvsHwSlBW8K1X3qNw+H6trqnknWDFQaQ2N9qG1b\nukhS0zUNobrukT3Jmuu3nh0a65TWzaG6T3ZuDVS95nNIxnXnnlmhuuYLh0N1S76Wfny/+JHPhMby\nR3lhE8G1kwCyRogByBohBiBrhBiArBFiALJGiAHIGiEGIGuEGICs0ex6EKz87YOhuoWlXaG6B/uX\nJmuGg0u2/tPA4aG69tJAqK7i6efB/+5Kz1+S1nXGmoQr+kOy5oXB16xiPK4mGwnVlawSquutpFfY\nvfS2n4fG+sH73xmqG3kp1iR8qOJMDEDWCDEAWSPEAGSNEAOQNUIMQNYIMQBZI8QAZI0QA5A1QgxA\n1ujYnyQ/c1myZn7psdBYv+k/PlTXWjeUrFkQ7P5vttgyy1FlWbLma2+NfQhWXyX2kX4DlfTS2Se1\nxLrYd5bbQnX9weW/Xxycl6xZ3rohNNaum2L32XZ+qOyQxZkYgKwRYgCyRogByBohBiBrhBiArBFi\nALJGiAHIGiEGIGuEGICs0bE/SRsuTq+hXg4+N3TUxdax/4uOdcmaf/jjmaGxfrrhpFBdU0Ns7flZ\nLel9mNeyJzRWxdPd/5LU3deZrBkpxz5z4OPH/D5Ud2nnU6G6u3rTV2G8PDInNNby+ZtCdWtDVYcu\nzsQAZI0QA5A1QgxA1ggxAFkjxABkjRADkDVCDEDWCDEAWSPEAGSNjv1Jqlvcl6yZHezEf2bvolDd\nJV+6MFnT9NNHQmMttljneTX1WnWfKzt9a7rIPTTWf2l2qO6ui78Qqvvydd9L1nQNzw2NdXbHc6G6\n5044L1lTfnZ9aKwcTSnEzGyjpF5JZUkj7r68GpMCgKhqnIm9xz3y1AgA1cd7YgCyNtUQc0m/MLNH\nzWzleAVmttLMVpvZ6mENTvHuAODVpvpy8ix37zKzN0m6z8yecfcHxha4+ypJqySp0+bG3m0FgKAp\nnYm5e1fx9xZJd0s6vRqTAoCoAw4xM2szs459X0s6T9KT1ZoYAERM5eXkAkl3m9m+cW53959VZVYA\nEHTAIebuGyS9vYpzycJfnfy7ZM13tp4dGmv9+ellliWpdSTQ9HhiellkSeEm0LBypXpjNVSx93pw\nKFRme/pDdS0/ji1jff3ujydrrvz3O0JjNdtwqG7bGfOTNbMP4WZXWiwAZI0QA5A1QgxA1ggxAFkj\nxABkjRADkDVCDEDWCDEAWSPEAGSN5akn6e3Nm5I1P3vlpNBYTUM7Q3UDpy9N1tT3j4TGqhsqh+o0\nejlZumxvrKs8wptKscK69HOv1ceen729JVRX39IcqrPd6eWm+itNobEWNu4K1Y3EpnbI4kwMQNYI\nMQBZI8QAZI0QA5A1QgxA1ggxAFkjxABkjRADkDVCDEDW6NifpBv+/CPJmp4L5obGWviOeaG6+r50\nN743xp6Poivie12sY78UWLPfhqt7lUAl0I1fF/zRtqHYlQ7RuXlgbv+x+czQWOvXHBmqO/6O9IeM\nVfGTEGYczsQAZI0QA5A1QgxA1ggxAFkjxABkjRADkDVCDEDWCDEAWaPZtVCaMydUNzwnvZxx8/Z0\nA6gkbT05tq7wwod2J2vKpeBy0pXY3KJ1kaZYbwo2nkbnVg60bgaacCclON62k9qSNUM/bQ+NdcJt\n60N15ZOOSRf9/qnQWKoEG5NnEM7EAGSNEAOQNUIMQNYIMQBZI8QAZI0QA5A1QgxA1ggxAFkjxABk\njY79gjU3heoiSyOPNMe653edPByqW/hgulu8biS2AHG5JXbIPbgcc91QoMM7OFaoE1+xqwRC81L8\ncfP+vaG63UsjgwWvhpgfW+a83Jw+pg2NDaGxKgOHYMe+md1iZlvM7Mkx2+aa2X1mtq74O3bNDgBU\nWeTl5Hclnb/ftqsk3e/uSyXdX3wPANMuGWLu/oCk7fttvkjSrcXXt0q6uMrzAoCQA31jf4G7dxdf\nvyJpQZXmAwCTMuXfTrq7S5rwnUozW2lmq81s9bAGp3p3APAqBxpiPWa2SJKKv7dMVOjuq9x9ubsv\nb1DsN4AAEHWgIXaPpMuKry+T9JPqTAcAJifSYnGHpIcknWBmm83s05KulfR+M1sn6X3F9wAw7ZJd\ncu6+YoKbzq3yXABg0ujY36epMVTmgbXsPfiots7rD9WNdKbfS2zs2hUaq641+L5ksJO9ri/QyR5d\n7z7asd+a/myCSnA/PXAFhiTZ3oFQ3XBnuuO9cUcpNta81lCdldOPr83qDI2lgdh+ziRcOwkga4QY\ngKwRYgCyRogByBohBiBrhBiArBFiALJGiAHIGiEGIGt07O8T7CofmJN+yIZmxe5ycE+sq7x+T3ot\nfm+JXXHQv7g9VDfUEXt+G24NrEwebNhv3hXr2G99Od1VXr+tL3anW7aFyir9sasrmrcEfj46Y/u5\nc0ns52P284ElrirBg5AhzsQAZI0QA5A1QgxA1ggxAFkjxABkjRADkDVCDEDWCDEAWaPZtVDu6k4X\nSWrfNDdZs+MtbaGx2p5KL7MsSbuWphtZl1zxTGiswxTbz4qnl+GWpIFy+keo4tV9rtw70pCs6d4T\na+rd2b00VLfwgdg+LHpwKFnT9e70/CWpfiDWoNqwPd2I633B5t8McSYGIGuEGICsEWIAskaIAcga\nIQYga4QYgKwRYgCyRogByBohBiBrdOwXdqw4LVS35cxysuZzZ/0sNNa315wdqqucMZKsWbvtTaGx\nGkqxpZH7BmPLXQ8NpX+EzGKd5x68SqCxMf14tDSml/SWpGOPeyVU139UrMv+5UfSx2HeO3pCY20f\nXBiqa97Rkaxp650fGqvywouhupmEMzEAWSPEAGSNEAOQNUIMQNYIMQBZI8QAZI0QA5A1QgxA1ggx\nAFmjY7+w7fyBUN37jnsuWdNaNxgaq9zdEqprOXZXsmZoJHYoZ7fsCdVF19iPdONHO/EHB2P7UKmk\nx4ve58s7ZoXqBnqbQnVNb0k/vpcf/UBorN/Nja3/rw+lS+7/n2WhoZZ86RDs2DezW8xsi5k9OWbb\nNWbWZWaPF38uPLjTBIDxRV5OflfS+eNsv8HdlxV/7q3utAAgJhli7v6ApO3TMBcAmLSpvLF/hZk9\nUbzcnDNRkZmtNLPVZrZ6WLH3igAg6kBD7EZJSyQtk9Qt6RsTFbr7Kndf7u7LGxR7cxQAog4oxNy9\nx93L7l6RdJOk06s7LQCIOaAQM7NFY769RNKTE9UCwMGUbMwxszsknSNpnpltlvRVSeeY2TJJLmmj\npMsP4hwBYELJEHP3FeNsvvkgzKWmKjtiyzH3DKSXAi53xE5wW3pidY3Hp5fEHhwphcZqaxgK1e3c\n2xyqi7SUlupiS2IPxfpTQ42sLQ2x5akHhmMNtqXm9JLYkjS4Pd3AfOML7w6NtWTWtlDd1oG2ZE1D\nb/DBzRCXHQHIGiEGIGuEGICsEWIAskaIAcgaIQYga4QYgKwRYgCyRogByBrLUxe8Pr3MsiR1NqSX\nse4anHBlolfp2BTrZJ/V2pes6elNX0kgSY11sc7z6PLO5Ur6ebA+2D1fX5++MkGSRgJXJzSUYmNF\n62KLl0vWnB6v5/l5obHec+a6UF2kY99jF3RkiTMxAFkjxABkjRADkDVCDEDWCDEAWSPEAGSNEAOQ\nNUIMQNYIMQBZo2N/n1jzvJoCHe/r++aHxmrfHPsw4eZS+j7rS7EdqA+udx/t2DdLX+nQGOzEHy7H\n2soHBxuSNU2Bx0ySmhpidbuDj0dze/qYNvwh9vmrTWfH5tYYueogcJxyxZkYgKwRYgCyRogByBoh\nBiBrhBiArBFiALJGiAHIGiEGIGuEGICs0bFfKPXH8rx3JN1t/fKeWaGxOnbHVm6vKN0tvnco3cUu\nSTsHW0J1ff2xrvJKYI39oaHYj1m5HDsG5b70vu4abA6NFf4sgcHY1QSdc3qTNS3Pxo7B5oHYZzVU\nAvtg5dh+5ogzMQBZI8QAZI0QA5A1QgxA1ggxAFkjxABkjRADkDVCDEDWaHYtlAZjzYBv6+xK1uwY\nbA2NZQOx55ATOnqSNbuDzZ1HtW8P1UWbQNsa0ssxh5ZPljQUXJ56c+/sZM2c5r2hsSKNopLUY7EG\n5lJg+e/WNemfISnWWC1JR7TuTNY8f+j2uqbPxMxssZn9ysyeNrOnzOzKYvtcM7vPzNYVf8faiwGg\niiKnAiOSvujuJ0p6p6TPmtmJkq6SdL+7L5V0f/E9AEyrZIi5e7e7P1Z83StpraQjJF0k6dai7FZJ\nFx+sSQLARCb1xr6ZHS3pVEkPS1rg7t3FTa9IWlDVmQFAQDjEzKxd0o8kfd7dd4+9zd1d0rgfbGdm\nK81stZmtHlbscxYBICoUYmbWoNEAu83d7yo295jZouL2RZK2jPdv3X2Vuy939+UNiv22BQCiIr+d\nNEk3S1rr7tePuekeSZcVX18m6SfVnx4AvL5In9iZkj4haY2ZPV5su1rStZLuNLNPS3pR0kcPzhQB\nYGLJEHP330oTLi16bnWnAwCTQ8d+YdayraG6v5v3TLLmwW3HhsbqPy7WH/wPC1Yna56Y83BorKPq\nh0N16+fFrgBotpFkTZPFOvaHg79n6q00JmsWlvpDYzUEO9kfPHxxqO5dLS8la1ZueW9orLd17ArV\nXT3v2WTNuWfND42VI66dBJA1QgxA1ggxAFkjxABkjRADkDVCDEDWCDEAWSPEAGSNEAOQNTr2C9t3\ntYXq+itDyZq1Gw4PjXXYotjD32DptefXDc0LjdXnO0J1zwzG9qGtLr28UqRGkvoqsVVO/jjSkaw5\ntnHcRVVe47DSnlDdznLscxPeXN+erCktiHXP/2DDklDdyjmPJWsa6mJXTYy7ntYMx5kYgKwRYgCy\nRogByBohBiBrhBiArBFiALJGiAHIGiEGIGs0uxYWzN2dLgqq2x18WINLI1dTo2JNj82WbuqVYs2i\nA94QGmt2qS9UF2mKjTbYRpbXlqRy8Pl+T2UgWVOZm27WlaSRcuw+O+rSy3XPbYot170tVDWzcCYG\nIGuEGICsEWIAskaIAcgaIQYga4QYgKwRYgCyRogByBohBiBrdOwXOhpjHd6tge7oSmusK77zxdhi\nwGWvJGtao0tAe3r+ktRWF+vYr1N6bgOVWMd+9Ck10o0fXeq6FFyQObqMdWQp8f43d8bG+nXsv2fT\nn6Yf33U7Yktiz1Vs+fKZhDMxAFkjxABkjRADkDVCDEDWCDEAWSPEAGSNEAOQNUIMQNYIMQBZo2O/\n4O/tCtV9cOEHkjXHv/JIaCw77ZRQ3aCn14HvrbSExtpebg/VlT32/NZbaU7WRLvnGyqxKx0GA1cA\n7LTW0FjNNhyqiyp7+gqAcnPswxUWfOvBUN0HvrUsWTNXz4XGylHyJ9XMFpvZr8zsaTN7ysyuLLZf\nY2ZdZvZ48efCgz9dAHi1yJnYiKQvuvtjZtYh6VEzu6+47QZ3v+7gTQ8AXl8yxNy9W1J38XWvma2V\ndMTBnhgAREzqjX0zO1rSqZIeLjZdYWZPmNktZjanynMDgKRwiJlZu6QfSfq8u++WdKOkJZKWafRM\n7RsT/LuVZrbazFYPK7ZcDABEhULMzBo0GmC3uftdkuTuPe5edveKpJsknT7ev3X3Ve6+3N2XNyj2\nWyoAiIr8dtIk3SxprbtfP2b7ojFll0h6svrTA4DXF/nt5JmSPiFpjZk9Xmy7WtIKM1smySVtlHT5\nQZkhALyOyG8nfytpvO68e6s/HQCYHDr2J2nklZ6qjTU0K7befWRd/7c0dofGOrkx1i0e6TyPGlas\nEz88XuQzByy2rn9kTXxJemCgesdqpCl2DBDDtZMAskaIAcgaIQYga4QYgKwRYgCyRogByBohBiBr\nhBiArNHsuo/FGhCtPt1E6cNDobGaHnomVHfKw5cma/o2dYbGKg3G9rNSX71mV2+MjeUN6SZWSVIl\nsA/R+Zdjj0fTllhT7OD8dGPvib/eFBorvSh5oS4wt0CD8Ghd9Y77dOFMDEDWCDEAWSPEAGSNEAOQ\nNUIMQNYIMQBZI8QAZI0QA5A1QgxA1synsUPXzP4o6cX9Ns+TtHXaJlF9uc9fyn8fcp+/lP8+TMf8\nj3L3+ftvnNYQG4+ZrXb35TWdxBTkPn8p/33Iff5S/vtQy/nzchJA1ggxAFmbCSG2qtYTmKLc5y/l\nvw+5z1/Kfx9qNv+avycGAFMxE87EAOCA1SzEzOx8M3vWzNab2VW1msdUmNlGM1tjZo+b2epazyfC\nzG4xsy1m9uSYbXPN7D4zW1f8PaeWc3w9E8z/GjPrKo7D42Z2YS3n+HrMbLGZ/crMnjazp8zsymJ7\nTsdgon2oyXGoyctJMytJek7S+yVtlvSIpBXu/vS0T2YKzGyjpOXunk1/j5n9maQ9kr7n7icX2/5R\n0nZ3v7Z4Qpnj7l+u5TwnMsH8r5G0x92vq+XcIsxskaRF7v6YmXVIelTSxZI+pXyOwUT78FHV4DjU\n6kzsdEnr3X2Duw9J+r6ki2o0lzcUd39A0vb9Nl8k6dbi61s1+gM5I00w/2y4e7e7P1Z83StpraQj\nlNcxmGgfaqJWIXaEpJfGfL9ZNXwQpsAl/cLMHjWzlbWezBQscPfu4utXJC2o5WQO0BVm9kTxcnPG\nvhQby8yOlnSqpIeV6THYbx+kGhwH3tifmrPc/U8kXSDps8VLnaz56PsLuf3K+kZJSyQtk9Qt6Ru1\nnU6ambVL+pGkz7v77rG35XIMxtmHmhyHWoVYl6TFY74/stiWFXfvKv7eIulujb5MzlFP8T7Hvvc7\nttR4PpPi7j3uXnb3iqSbNMOPg5k1aPQ//23uflexOatjMN4+1Oo41CrEHpG01MyOMbNGSR+TdE+N\n5nJAzKyteFNTZtYm6TxJT77+v5qx7pF0WfH1ZZJ+UsO5TNq+//yFSzSDj4OZmaSbJa119+vH3JTN\nMZhoH2p1HGrW7Fr8+vWbkkqSbnH3r9dkIgfIzI7V6NmXNPr5nbfnsA9mdoekczS66kCPpK9K+rGk\nOyW9WaOrjHzU3Wfkm+cTzP8cjb6EcUkbJV0+5v2lGcXMzpL0G0lrJO37MMirNfqeUi7HYKJ9WKEa\nHAc69gFkjTf2AWSNEAOQNUIMQNYIMQBZI8QAZI0QA5A1QgxA1ggxAFn7P7y0g0Te1sBzAAAAAElF\nTkSuQmCC\n","text/plain":["<Figure size 1152x360 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["target is:  2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OnRljn7h9jLj","colab_type":"code","colab":{}},"source":["class FashionDataSet(torch.utils.data.Dataset):\n","    def __init__(self, dataset, indices, transform=None):\n","        self.dataset = dataset\n","        self.transform = transform\n","        self.indices = indices\n","    \n","    def __len__(self):\n","        return len(self.indices)\n","    \n","    def __getitem__(self, idx):\n","        image, label = self.dataset[self.indices[idx]]\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        return image, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbmMTrlp2KIK","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","\n","def get_loaders(dataet, batch_size=128, train_transform=None, valid_transform=None):\n","    indices = np.arange(len(train_set))\n","\n","    train_indeces, valid_indeces = train_test_split(indices, random_state=42)\n","\n","    train_dataset = FashionDataSet(dataet, train_indeces, train_transform)\n","    valid_dataset = FashionDataSet(dataet, valid_indeces, valid_transform)\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, \n","        batch_size=batch_size, \n","        shuffle=True, \n","        num_workers=8\n","    )\n","\n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset, \n","        batch_size=batch_size, \n","        shuffle=False, \n","        num_workers=8\n","    )\n","\n","    loaders = {\n","        'train': train_loader, \n","        'valid': valid_loader\n","    }\n","\n","    return loaders"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9gVU_2hP88QC","colab_type":"code","colab":{}},"source":["# torchvision.models documentation recomendation\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","\n","train_transform = transforms.Compose([\n","                                transforms.ToTensor(),\n","                                transforms.Normalize(mean, std)])\n","test_transform = transforms.Compose([\n","                                transforms.ToTensor(),\n","                                transforms.Normalize(mean, std)])\n","\n","\n","loaders = get_loaders(\n","    train_set,\n","    batch_size=128,\n","    train_transform=None,\n","    valid_transform=None\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6OxjP3wkPLWg","colab_type":"code","colab":{}},"source":["\n","class Network(torch.nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n","    # self.conv1_dp = nn.Dropout() \n","    # self.conv1_bn = nn.BatchNorm2d(num_features=6)\n","    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n","\n","    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n","    # self.fc1_dp = nn.Dropout() \n","    # self.fc1_bn = nn.BatchNorm1d(num_features=120)\n","    self.fc2 = nn.Linear(in_features=120, out_features=60)\n","    self.out = nn.Linear(in_features=60, out_features=10)\n","\n","  def forward(self, t):\n","    # conv 1\n","    t = self.conv1(t)\n","    # t = self.conv1_dp(t)\n","    # t = self.conv1_bn(t)\n","    t = F.relu(t)\n","    t = F.max_pool2d(t, kernel_size=2, stride=2)\n","\n","    # conv 2\n","    t = self.conv2(t)\n","    t = F.relu(t)\n","    t = F.max_pool2d(t, kernel_size=2, stride=2)\n","\n","    # fc1\n","    t = t.reshape(-1, 12*4*4)\n","    t = self.fc1(t)\n","    # t = self.fc1_dp(t)\n","    # t = self.fc1_bn(t)\n","    t = F.relu(t)\n","\n","    # fc2\n","    t = self.fc2(t)\n","    t = F.relu(t)\n","\n","    # output\n","    t = self.out(t)\n","\n","    return t"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ikuKEUKHW5V_","colab_type":"code","colab":{}},"source":["model = Network()\n","\n","device = torch.device('cuda')\n","model.to(device)\n","\n","epoch = 15\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","\n","train_loader = loaders['train']\n","valid_loader = loaders['valid']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCcVQSP8SQC6","colab_type":"code","outputId":"1b24fc69-9254-4263-f986-317667864e92","executionInfo":{"status":"ok","timestamp":1581665515341,"user_tz":-240,"elapsed":58,"user":{"displayName":"Baka F","photoUrl":"","userId":"05022197215042441803"}},"colab":{"base_uri":"https://localhost:8080/","height":491}},"source":["model, train_loss, test_loss = train(model, train_loader, valid_loader, epoch, optimizer, criterion, path=None)"],"execution_count":77,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>run</th>\n","      <th>epoch</th>\n","      <th>loss</th>\n","      <th>accuracy</th>\n","      <th>epoch duration</th>\n","      <th>run duration</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.480158</td>\n","      <td>0.821333</td>\n","      <td>1.622228</td>\n","      <td>6.839874</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.410558</td>\n","      <td>0.850733</td>\n","      <td>1.678164</td>\n","      <td>13.750110</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0.383399</td>\n","      <td>0.861800</td>\n","      <td>1.666404</td>\n","      <td>20.715991</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0.371796</td>\n","      <td>0.864133</td>\n","      <td>1.622088</td>\n","      <td>27.750661</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0.362715</td>\n","      <td>0.867067</td>\n","      <td>1.637912</td>\n","      <td>34.815892</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>0.397154</td>\n","      <td>0.861133</td>\n","      <td>1.600117</td>\n","      <td>41.668633</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>0.339937</td>\n","      <td>0.878800</td>\n","      <td>1.636061</td>\n","      <td>48.433888</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>0.361787</td>\n","      <td>0.869200</td>\n","      <td>1.616295</td>\n","      <td>55.199541</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>0.337661</td>\n","      <td>0.878800</td>\n","      <td>1.647800</td>\n","      <td>62.016709</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>0.350296</td>\n","      <td>0.873667</td>\n","      <td>1.607516</td>\n","      <td>68.679837</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>0.357794</td>\n","      <td>0.870933</td>\n","      <td>1.647097</td>\n","      <td>75.488715</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>0.318781</td>\n","      <td>0.885267</td>\n","      <td>1.780129</td>\n","      <td>82.499653</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1</td>\n","      <td>13</td>\n","      <td>0.325858</td>\n","      <td>0.886200</td>\n","      <td>1.807424</td>\n","      <td>89.411757</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>14</td>\n","      <td>0.340763</td>\n","      <td>0.879800</td>\n","      <td>1.715747</td>\n","      <td>96.312414</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1</td>\n","      <td>15</td>\n","      <td>0.332827</td>\n","      <td>0.882467</td>\n","      <td>1.657326</td>\n","      <td>103.057796</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    run  epoch      loss  accuracy  epoch duration  run duration\n","0     1      1  0.480158  0.821333        1.622228      6.839874\n","1     1      2  0.410558  0.850733        1.678164     13.750110\n","2     1      3  0.383399  0.861800        1.666404     20.715991\n","3     1      4  0.371796  0.864133        1.622088     27.750661\n","4     1      5  0.362715  0.867067        1.637912     34.815892\n","5     1      6  0.397154  0.861133        1.600117     41.668633\n","6     1      7  0.339937  0.878800        1.636061     48.433888\n","7     1      8  0.361787  0.869200        1.616295     55.199541\n","8     1      9  0.337661  0.878800        1.647800     62.016709\n","9     1     10  0.350296  0.873667        1.607516     68.679837\n","10    1     11  0.357794  0.870933        1.647097     75.488715\n","11    1     12  0.318781  0.885267        1.780129     82.499653\n","12    1     13  0.325858  0.886200        1.807424     89.411757\n","13    1     14  0.340763  0.879800        1.715747     96.312414\n","14    1     15  0.332827  0.882467        1.657326    103.057796"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"dcCWoo19TW3T","colab_type":"code","colab":{}},"source":["model = load_latest_model(model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"whEHS4zLTW7l","colab_type":"code","outputId":"c1acc6ce-fbfd-478c-8545-313cd5131385","executionInfo":{"status":"ok","timestamp":1581665515346,"user_tz":-240,"elapsed":100485,"user":{"displayName":"Baka F","photoUrl":"","userId":"05022197215042441803"}},"colab":{"base_uri":"https://localhost:8080/","height":279}},"source":["check_overfitted(train_loss, test_loss)"],"execution_count":79,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"eXF25Yl_TW6B","colab_type":"code","outputId":"16c25404-7d51-488f-cd50-5eafd6d642fb","executionInfo":{"status":"ok","timestamp":1581665517185,"user_tz":-240,"elapsed":101172,"user":{"displayName":"Baka F","photoUrl":"","userId":"05022197215042441803"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test(model, valid_loader)"],"execution_count":80,"outputs":[{"output_type":"stream","text":["Accuracy: 88.5483\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8zd4owo8aje1","colab_type":"code","outputId":"a3455bb8-3324-4b0a-a088-dd7219e3c44b","executionInfo":{"status":"ok","timestamp":1581665519671,"user_tz":-240,"elapsed":103031,"user":{"displayName":"Baka F","photoUrl":"","userId":"05022197215042441803"}},"colab":{"base_uri":"https://localhost:8080/","height":252}},"source":["test_per_class(model, valid_loader, criterion, np.arange(10))"],"execution_count":81,"outputs":[{"output_type":"stream","text":["Test Loss: 0.317749\n","\n","Test Accuracy of     0: 81% (1205/1486)\n","Test Accuracy of     1: 97% (1507/1546)\n","Test Accuracy of     2: 83% (1249/1499)\n","Test Accuracy of     3: 91% (1356/1484)\n","Test Accuracy of     4: 81% (1234/1515)\n","Test Accuracy of     5: 95% (1422/1493)\n","Test Accuracy of     6: 67% (1014/1505)\n","Test Accuracy of     7: 95% (1408/1476)\n","Test Accuracy of     8: 96% (1445/1500)\n","Test Accuracy of     9: 96% (1439/1496)\n","\n"," Test Accuracy (Overall): 88% (13279/15000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fuzxw8GicQO-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}